{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pypfopt.efficient_frontier import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns\n",
    "from pypfopt import discrete_allocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'UAA': 0.0, 'AAPL': 0.09202, 'AMZN': 0.07158, 'BBY': 0.06129, 'FB': 0.19856, 'T': 0.0, 'BABA': 0.09642, 'MA': 0.24562, 'SHLD': 0.0, 'RRC': 0.0, 'JPM': 0.0, 'SBUX': 0.03769, 'PFE': 0.18413, 'BAC': 0.0, 'GOOG': 0.01269, 'XOM': 0.0, 'GM': 0.0, 'AMD': 0.0, 'GE': 0.0, 'WMT': 0.0}\n",
      "Expected annual return: 33.0%\n",
      "Annual volatility: 21.7%\n",
      "Sharpe Ratio: 1.43\n",
      "Wall time: 316 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in price data\n",
    "df = pd.read_csv(\"tests/stock_prices.csv\", parse_dates=True, index_col=\"date\")\n",
    "\n",
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(df)\n",
    "S = risk_models.sample_cov(df)\n",
    "\n",
    "# Optimise for maximal Sharpe ratio\n",
    "ef = EfficientFrontier(mu, S)\n",
    "raw_weights = ef.max_sharpe()\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 out of 20 tickers were removed\n",
      "Funds remaining: 12.15\n",
      "{'AMZN': 0, 'BBY': 9, 'FB': 12, 'MA': 14, 'SBUX': 6, 'BABA': 5, 'AAPL': 5, 'GOOG': 1, 'PFE': 51}\n",
      "Funds remaining: $12.15\n"
     ]
    }
   ],
   "source": [
    "latest_prices = discrete_allocation.get_latest_prices(df)\n",
    "allocation, leftover = discrete_allocation.portfolio(\n",
    "    raw_weights, latest_prices, total_portfolio_value=10000\n",
    ")\n",
    "print(allocation)\n",
    "print(\"Funds remaining: ${:.2f}\".format(leftover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'374843': 0.0, '367902': 0.46642, '372549': 0.0, '376335': 0.0, '349145': 0.0, '332613': 0.0, '378361': 0.0, '361057': 0.53358, '379751': 0.0, '208007': 0.0}\n",
      "Expected annual return: 3.2%\n",
      "Annual volatility: 10.4%\n",
      "Sharpe Ratio: 0.11\n",
      "Wall time: 202 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Read in price data\n",
    "df = pd.read_csv(\"data/data.txt\", parse_dates=True, index_col=\"TIME\")\n",
    "\n",
    "# Calculate expected returns and sample covariance\n",
    "mu = expected_returns.mean_historical_return(df)\n",
    "S = risk_models.sample_cov(df)\n",
    "\n",
    "# Optimise for maximal Sharpe ratio\n",
    "ef = EfficientFrontier(mu, S)\n",
    "raw_weights = ef.max_sharpe()\n",
    "cleaned_weights = ef.clean_weights()\n",
    "print(cleaned_weights)\n",
    "ef.portfolio_performance(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 out of 10 tickers were removed\n",
      "Funds remaining: 196.40\n",
      "{'367902': 14, '361057': 4}\n",
      "Funds remaining: $196.40\n"
     ]
    }
   ],
   "source": [
    "latest_prices = discrete_allocation.get_latest_prices(df)\n",
    "allocation, leftover = discrete_allocation.portfolio(\n",
    "    raw_weights, latest_prices, total_portfolio_value=10000\n",
    ")\n",
    "print(allocation)\n",
    "print(\"Funds remaining: ${:.2f}\".format(leftover))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 768.68,  153.37,  234.35, ...,  233.16,  144.72,  571.33],\n",
       "       [ 768.68,  153.37,  234.35, ...,  234.95,  144.72,  571.33],\n",
       "       [ 768.68,  153.37,  234.35, ...,  238.73,  144.72,  571.33],\n",
       "       ...,\n",
       "       [1310.88,  151.27,  294.25, ...,  336.41,  145.67,  587.83],\n",
       "       [1310.88,  151.27,  294.43, ...,  334.39,  145.85,  587.83],\n",
       "       [1310.88,  151.27,  294.67, ...,  335.45,  145.76,  587.83]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6215, 10)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Evaluator():\n",
    "    def __init__(self, df, from_percent, to_percent):\n",
    "        n = df.values.shape[0]\n",
    "        from_index = int(n * from_percent)\n",
    "        to_index = min(n - 1, int(n * to_percent))\n",
    "        self.returns=df.values[to_index]-df.values[from_index]\n",
    "\n",
    "    def evaluate_asset(self, normalized_asset, cut_threshold=0.04):\n",
    "        normalized_asset[normalized_asset < cut_threshold] = 0\n",
    "        return (normalized_asset * self.returns).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stupid_normalize(x):\n",
    "    return x / x.sum()\n",
    "\n",
    "def normalize(x):\n",
    "    x[x<0]=np.exp(x[x<0])\n",
    "    x[x>=0]=x[x>=0]+1\n",
    "    return stupid_normalize(x)\n",
    "\n",
    "def normalized_asset(b, X):\n",
    "    return normalize(X.dot(b[1:])+b[0])\n",
    "\n",
    "def regularization(b):\n",
    "    return (b ** 2).sum()\n",
    "\n",
    "def obj_function(b, X, k, evaluate):\n",
    "    assert X.shape[1] == b.shape[0] - 1, \"{} != {}\".format(X.shape[1], b.shape[0])\n",
    "    return -evaluate(normalized_asset(b, X)) + k * regularization(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_features(file_name):\n",
    "    fdf = pd.read_csv(file_name)\n",
    "    return fdf.drop('accountId', axis=1).dropna(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k is regularization\n",
    "def cool_algo(series_path, static_path, k=0.01, train_test_fragmentation=0.8):\n",
    "    df = pd.read_csv(series_path, parse_dates=True, index_col=\"TIME\")\n",
    "    X = prepare_features(static_path).values\n",
    "    print(\"{} features extracted\".format(X.shape[0]))\n",
    "\n",
    "    b_len = X.shape[1] + 1\n",
    "    xinit = np.array([1.0 / b_len] * b_len)\n",
    "\n",
    "    #bnds = [(0, None)] * b_len\n",
    "    \n",
    "    # the greater value is for the better res\n",
    "    train_evaluator = Evaluator(df, 0.0, train_test_fragmentation)\n",
    "    test_evaluator = Evaluator(df, train_test_fragmentation, 1.0)\n",
    "    def evaluate(normalized_asset):\n",
    "        return train_evaluator.evaluate_asset(normalized_asset)\n",
    "\n",
    "    res = minimize(obj_function, args=(X, k, evaluate), x0=xinit, method='SLSQP')\n",
    "\n",
    "    asset = normalized_asset(res.x, X)\n",
    "    print(\"Train result:\", evaluate(asset))\n",
    "    print(\"Test result:\", test_evaluator.evaluate_asset(asset))\n",
    "    print(\"Asset:\", asset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features extracted\n",
      "Train result: 670.5657601175449\n",
      "Test result: -128.4015288419407\n",
      "Asset: [0.99993403 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "cool_algo('data/10traders_1month.txt', 'data/10traders.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cool_algo('data/500traders_1year.txt', 'data/500traders.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
